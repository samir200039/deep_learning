{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyroLKmwbEhm"
      },
      "outputs": [],
      "source": [
        "\"\"\" Conduct hyperparameter tuning for a CNN model on a chosen dataset. Focus on optimizing\n",
        "parameters like the number of filters, kernel size, learning rate, and epochs. Document the\n",
        "process and results.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkHfO2HsbEhn",
        "outputId": "23d17d65-83bd-47e2-b4d8-b46403da4287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 03m 46s]\n",
            "val_accuracy: 0.5830666422843933\n",
            "\n",
            "Best val_accuracy So Far: 0.6513000130653381\n",
            "Total elapsed time: 00h 35m 44s\n",
            "\n",
            "The optimal number of filters is 128,\n",
            "the optimal kernel size is 5,\n",
            "the optimal number of units in the dense layer is 128,\n",
            "the optimal dropout rate is 0.2,\n",
            "and the optimal learning rate is 0.0006767358590353206.\n",
            "\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 8s 5ms/step - loss: 1.5516 - accuracy: 0.4392 - val_loss: 1.2910 - val_accuracy: 0.5543\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2503 - accuracy: 0.5563 - val_loss: 1.1531 - val_accuracy: 0.5979\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1123 - accuracy: 0.6059 - val_loss: 1.1015 - val_accuracy: 0.6123\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0160 - accuracy: 0.6393 - val_loss: 1.0699 - val_accuracy: 0.6288\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9241 - accuracy: 0.6726 - val_loss: 1.0603 - val_accuracy: 0.6380\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8388 - accuracy: 0.7032 - val_loss: 1.0410 - val_accuracy: 0.6509\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7707 - accuracy: 0.7265 - val_loss: 1.0720 - val_accuracy: 0.6426\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.6979 - accuracy: 0.7529 - val_loss: 1.1039 - val_accuracy: 0.6513\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6312 - accuracy: 0.7757 - val_loss: 1.1112 - val_accuracy: 0.6530\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5698 - accuracy: 0.7958 - val_loss: 1.1945 - val_accuracy: 0.6501\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5195 - accuracy: 0.8127 - val_loss: 1.1741 - val_accuracy: 0.6579\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4740 - accuracy: 0.8321 - val_loss: 1.2253 - val_accuracy: 0.6500\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4381 - accuracy: 0.8450 - val_loss: 1.2937 - val_accuracy: 0.6427\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3932 - accuracy: 0.8605 - val_loss: 1.4147 - val_accuracy: 0.6376\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3603 - accuracy: 0.8706 - val_loss: 1.3866 - val_accuracy: 0.6532\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3326 - accuracy: 0.8821 - val_loss: 1.4849 - val_accuracy: 0.6445\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3097 - accuracy: 0.8903 - val_loss: 1.5513 - val_accuracy: 0.6461\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2871 - accuracy: 0.8991 - val_loss: 1.5848 - val_accuracy: 0.6456\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2688 - accuracy: 0.9052 - val_loss: 1.6863 - val_accuracy: 0.6426\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2505 - accuracy: 0.9118 - val_loss: 1.7078 - val_accuracy: 0.6376\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7072 - accuracy: 0.6411\n",
            "Test accuracy: 0.6410999894142151\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(\n",
        "        filters=hp.Int('filters', min_value=32, max_value=128, step=16),\n",
        "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(\n",
        "        units=hp.Int('units', min_value=32, max_value=128, step=16),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
        "        ),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  # Number of hyperparameter combinations to try\n",
        "    executions_per_trial=3,  # Number of models to build and fit for each trial\n",
        "    directory='my_dir',\n",
        "    project_name='cnn_hyperparameter_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
        ")\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The optimal number of filters is {best_hps.get('filters')},\n",
        "the optimal kernel size is {best_hps.get('kernel_size')},\n",
        "the optimal number of units in the dense layer is {best_hps.get('units')},\n",
        "the optimal dropout rate is {best_hps.get('dropout')},\n",
        "and the optimal learning rate is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}